![Build Status](https://github.com/alawryaguila/multi-view-ae/actions/workflows/ci.yml/badge.svg)
[![Documentation Status](https://readthedocs.org/projects/multi-view-ae/badge/?version=latest)](https://multi-view-ae.readthedocs.io/en/latest/?badge=latest)
[![Python Version](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10%20-blue)](https://github.com/alawryaguila/multi-view-ae)

# Multi-view-AE: Multi-modal subspace learning using autoencoders

This repository contains various multi-view autoencoder models built in Pytorch and Pytorch-Lightning. 

Documentation is available at https://multi-view-ae.readthedocs.io/en/latest/

### Installation
Clone this repository and move to folder:
```bash
git clone https://github.com/alawryaguila/multi-view-AE
cd multi-view-AE
```

Create the customised python environment:
```bash
conda create --name mvae python=3.9
```

Activate python environment:
```bash
conda activate mvae
```

Install the ``multi-view-AE`` package:
```bash
pip install ./
```

### Contribution guidelines
Contribution guidelines are available at https://multi-view-ae.readthedocs.io/en/latest/
