# @package _global_

model:
  z_dim: 512
  beta: 2.5 
  alpha: 0.83333333333 
  learning_rate: 0.001
  seed_everything: True
  seed: 42
  return_mean: False 

datamodule:
  _target_: MMNISTdataloader.MMNISTDataModule
  batch_size: null
  is_validate: False
  dataset:
    _target_: MMNISTdataloader.MVDataset
    data_dir: '/path/to/training/data'
    is_path_ds: True
    views: [0, 1, 2, 3, 4]

encoder:
  default: 
      _target_: autoencoder_functions.cnn.VariationalEncoder

      enc_dist:
        _target_: multiviewae.base.distributions.Normal


decoder:
  default: 
      _target_: autoencoder_functions.cnn.Decoder

      dec_dist:
        _target_: multiviewae.base.distributions.Laplace
        scale: 0.75

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: 'gpu'
  gpus: 1
  max_epochs: 10
  deterministic: True
  log_every_n_steps: 2

optimizer:
  _target_: torch.optim.Adam
  amsgrad: True