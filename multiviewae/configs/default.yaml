# @package _global_

# TODO: _target_ should not be replaceable except for enc/dec _target_ and enc_dist/dec_dist _target_

defaults:
  - _self_
  - model_type: null

out_dir: ${hydra.runtime.cwd}/outputs/${model_name}/${now:%Y-%m-%d_%H%M%S}

hydra:
  # TODO: this does not work... I want to save yaml files, i think it is not enabled when using initialize/compose
  output_subdir: ${out_dir}/.hydra
  run:
    dir: ${out_dir}

model:
  save_model: False #whether to save the model

  seed_everything: True
  seed: 42

  # TODO: support multi-dimensional tuple
  z_dim: 5 #dimensionality of the latent space
  learning_rate: 0.001  # learning rate for both encoder/decoder

  #sparsity of the encoding distribution.
  sparse: False  #NOTE: setting sparse to True enforces a uniform prior over the latents
  threshold: 0

datamodule:
  _target_: multiviewae.base.dataloaders.MultiviewDataModule
  batch_size: null
  is_validate: True
  train_size: 0.9
  dataset:
    _target_: multiviewae.base.datasets.MVDataset

encoder:  # uses default mlp for all inputs
  default:
      _target_: multiviewae.architectures.mlp.Encoder

      hidden_layer_dim: []
      bias: True  # only applies to linear layers
      non_linear: False

      enc_dist:
        _target_: multiviewae.base.distributions.Default

decoder: # uses default mlp for all inputs
  default:
      _target_: multiviewae.architectures.mlp.Decoder

      hidden_layer_dim: []
      bias: True  # only applies to linear layers
      non_linear: False

      dec_dist:
        _target_: multiviewae.base.distributions.Default

prior:
  _target_: multiviewae.base.distributions.Normal
  loc: 0.
  scale: 1.

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: "auto"
  max_epochs: 10
  deterministic: False
  log_every_n_steps: 2

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val_loss"
    mode: "min"
    save_last: True
    dirpath: ${out_dir}

  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val_loss"
    mode: "min"
    patience: 50
    min_delta: 0.001
    verbose: True

logger: #TODO: check other logger frameworks work
  _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger

  save_dir: ${out_dir}/logs
